# План экспериментов

## Общая структура

Эксперименты организованы в три этапа:
1. **Этап 1: Обучение алгоритмов** - обучение RL-алгоритмов и baseline эвристик на основном профиле нагрузки
2. **Этап 2: Валидация (Reconciliation)** - тестирование обученных моделей на основном и альтернативном профилях
3. **Этап 3: Сравнительный анализ** - статистический анализ и сравнение результатов

---

## Профили нагрузки

### Профиль A (Основной) - Эмпирический суточный профиль
**Характеристики:**
- Основан на эмпирических данных распределения нагрузки в течение суток
- Неравномерный профиль с выраженными пиками:
  - Ночь (00:00-05:00): 0.89 → 0.28 (падение)
  - Утро (06:00-11:00): 0.22 → 0.63 (рост)
  - День (12:00-17:00): 0.73-0.81 (высокая стабильная)
  - Вечер (18:00-23:00): 0.85 → 1.0 → 0.95 (пик в 21:00)
- Используется для обучения и проверки стабильности

### Профиль B (Альтернативный) - Модифицированный профиль
**Характеристики:**
- Модифицированная версия основного профиля для проверки обобщения
- Варианты модификации:
  - **Вариант 1:** Сдвиг пика (пик в другое время суток)
  - **Вариант 2:** Изменение амплитуды (более/менее выраженные пики)
  - **Вариант 3:** Другой паттерн (например, более равномерный)
  - **Вариант 4:** Синтетический синусоидальный профиль
- Используется для проверки обобщения

**Рекомендация:** Использовать вариант с изменением амплитуды или сдвигом пика для реалистичности.

---

## Этап 1: Обучение алгоритмов

### Цель
Обучить модели RL-алгоритмов и выполнить baseline эвристики на основном профиле нагрузки (Профиль A).

### Параметры обучения

**RL-алгоритмы (PPO, SAC, TD3):**
- **Профиль нагрузки:** Профиль A (полный суточный профиль)
- **Количество запусков:** 3 независимых запуска
- **Реальное время каждого запуска:** 24 часа (фиксировано)
- **Количество шагов (зависит от скорости алгоритма):**
  - **SAC:** 1600 шагов за 24 часа реального времени
  - **TD3:** 960 шагов за 24 часа реального времени
  - **PPO:** 960 шагов за 24 часа реального времени
- **Конфигурация кластера:** 4 базовые станции (bs1, bs2, bs3, bs4)
- **Шаг дискретизации:** 10 секунд
- **Результат:** 3 обученные модели на алгоритм
- **Важно:** Все алгоритмы обучаются одинаковое реальное время (24 часа), но на разном количестве шагов. Это справедливо для сравнения - мы сравниваем, что алгоритм может сделать за фиксированное время.

**Baseline эвристики:**
- **Профиль нагрузки:** Профиль A (полный суточный профиль)
- **Количество запусков:** 3 независимых запуска
- **Реальное время каждого запуска:** 24 часа (фиксировано)
- **Количество шагов:** определяется скоростью выполнения (аналогично RL-алгоритмам)
- **Типы:** static, greedy_latency

### Расчет длительности обучения

**Фиксированное реальное время обучения:** 24 часа на запуск

**Реальная скорость выполнения (из экспериментов):**
- **SAC:** 100 шагов за 1.5 часа реального времени
- **TD3:** 100 шагов за 2.5 часа реального времени
- **PPO:** 100 шагов за 2.5 часа реального времени

**Количество шагов за 24 часа реального времени:**

**SAC:**
- 24 часа / 1.5 часа × 100 шагов = **1600 шагов** за 24 часа реального времени
- 3 запуска × 24 часа = **72 часа (~3 дня) на алгоритм**

**TD3 и PPO:**
- 24 часа / 2.5 часа × 100 шагов = **960 шагов** за 24 часа реального времени
- 3 запуска × 24 часа = **72 часа (~3 дня) на алгоритм**

**Итого при последовательном выполнении:**
- SAC: 3 запуска × 24 часа = 72 часа (~3 дня)
- TD3: 3 запуска × 24 часа = 72 часа (~3 дня)
- PPO: 3 запуска × 24 часа = 72 часа (~3 дня)
- **Всего:** ~216 часов (~9 дней)

**С параллелизацией:**
- Можно запускать все 3 алгоритма параллельно
- **Время:** ~3 дня (все алгоритмы обучаются одинаковое реальное время)

**Примечание:** 
- Разные алгоритмы обучаются на разном количестве шагов (SAC: 1600, TD3/PPO: 960), но одинаковое реальное время (24 часа)
- Это справедливо для сравнения - мы сравниваем, что алгоритм может сделать за фиксированное время
- Количество шагов соответствует разной симулированной длительности для каждого алгоритма

### Файлы конфигурации

- `ppo_training.json` - PPO с оптимизированными гиперпараметрами
- `sac_training.json` - SAC с оптимизированными гиперпараметрами
- `td3_training.json` - TD3 с оптимизированными гиперпараметрами
- `heuristic_static.json` - Static baseline
- `heuristic_greedy_latency.json` - Greedy latency baseline

---

## Этап 2: Валидация (Reconciliation)

### Цель
Оценить способность обученных моделей к стабильности и обобщению на различных профилях нагрузки.

### Структура reconciliation экспериментов

Для каждой обученной модели (из Этапа 1):

#### 2.1. Проверка стабильности (Профиль A)
- **Профиль:** Профиль A - тот же, что использовался для обучения
- **Реальное время:** 24 часа (фиксировано)
- **Количество шагов:**
  - SAC: 1600 шагов
  - TD3/PPO: 960 шагов
- **Цель:** Проверить стабильность работы на тех же данных

#### 2.2. Проверка обобщения (Профиль B)
- **Профиль:** Профиль B - альтернативный профиль
- **Реальное время:** 24 часа (фиксировано)
- **Количество шагов:**
  - SAC: 1600 шагов
  - TD3/PPO: 960 шагов
- **Цель:** Проверить способность к обобщению на новых данных

### Baseline эвристики на обоих профилях

Для baseline эвристик также выполняются reconciliation на обоих профилях:
- Static на Профиле A (24 часа)
- Static на Профиле B (24 часа)
- Greedy latency на Профиле A (24 часа)
- Greedy latency на Профиле B (24 часа)

### Итого reconciliation экспериментов

**Для RL-алгоритмов:**
- 3 алгоритма × 3 модели × 2 профиля = **18 reconciliation экспериментов**

**Для baseline:**
- 2 эвристики × 2 профиля = **4 reconciliation эксперимента** (по 1 на каждый профиль)

**Общее время reconciliation (последовательно):**
- Все алгоритмы: 9 моделей × 2 профиля × 24 часа = 432 часа (~18 дней)
- **С параллелизацией:** можно сократить до **~2-3 дней** (все reconciliation можно запускать параллельно)

---

## Этап 3: Сравнительный анализ

### Метрики для сравнения

**Метрики производительности:**
- Средняя сетевая задержка (AvgLatency)
- Перцентили задержки (p50, p95, p99, p99.9)
- Коэффициент соблюдения SLA
- Утилизация ресурсов кластера (CPU, RAM)
- Частота изменений конфигурации (миграций подов)
- Стабильность производительности во времени

**Метрики обучения:**
- Скорость сходимости
- Стабильность обучения
- Воспроизводимость результатов

**Метрики обобщения:**
- Разница в производительности между Профилем A и B
- Деградация производительности на новом профиле
- Способность адаптироваться к новым паттернам

**Вычислительные метрики:**
- Время инференса
- Throughput решений
- Потребление памяти
- Нагрузка на CPU

### Статистический анализ

- Вычисление средних значений и стандартных отклонений
- Доверительные интервалы (95%, метод бутстрепа)
- ANOVA / Kruskal-Wallis для сравнения алгоритмов
- Post-hoc тесты (Tukey / Dunn) для попарных сравнений
- Сравнение производительности на Профиле A vs Профиле B (t-test / Wilcoxon)

---

## Рекомендуемый порядок выполнения

### Фаза 1: Baseline на обоих профилях (2-3 дня)
1. Запустить `heuristic_static.json` на Профиле A (5 запусков)
2. Запустить `heuristic_greedy_latency.json` на Профиле A (5 запусков)
3. Запустить reconciliation для static на Профиле A и B
4. Запустить reconciliation для greedy_latency на Профиле A и B
5. Получить baseline метрики для сравнения

### Фаза 2: Обучение RL-алгоритмов (3 дня с 3 VM)
1. **PPO:** 3 запуска на Профиле A (каждый = 24 часа реального времени, 960 шагов)
   - 3 запуска выполняются параллельно на 3 VM
   - Время: 1 день (3 прогона параллельно)
2. **SAC:** 3 запуска на Профиле A (каждый = 24 часа реального времени, 1600 шагов)
   - 3 запуска выполняются параллельно на 3 VM
   - Время: 1 день (3 прогона параллельно)
3. **TD3:** 3 запуска на Профиле A (каждый = 24 часа реального времени, 960 шагов)
   - 3 запуска выполняются параллельно на 3 VM
   - Время: 1 день (3 прогона параллельно)
4. Сохранить веса всех 9 обученных моделей (3 алгоритма × 3 модели)
5. **Итого:** 3 дня (каждый алгоритм = 1 день, можно запускать последовательно или параллельно)

### Фаза 3: Reconciliation - Стабильность (3 дня с 3 VM)
Для каждой из 9 обученных моделей:
1. Reconciliation на Профиле A (24 часа реального времени) - проверка стабильности
2. Количество шагов зависит от алгоритма (SAC: 1600, TD3/PPO: 960)
3. Запускаются по 3 параллельно на 3 VM
4. **Итого:** 9 reconciliation экспериментов
5. **Время:** 9 reconciliation / 3 VM = 3 батча × 24 часа = 3 дня

### Фаза 4: Reconciliation - Обобщение (3 дня с 3 VM)
Для каждой из 9 обученных моделей:
1. Reconciliation на Профиле B (24 часа реального времени) - проверка обобщения
2. Количество шагов зависит от алгоритма (SAC: 1600, TD3/PPO: 960)
3. Запускаются по 3 параллельно на 3 VM
4. **Итого:** 9 reconciliation экспериментов
5. **Время:** 9 reconciliation / 3 VM = 3 батча × 24 часа = 3 дня

### Фаза 5: Анализ (2-3 дня)
1. Сбор всех метрик
2. Статистический анализ
3. Сравнение стабильности и обобщения
4. Визуализация результатов
5. Формирование выводов

---

## Итоговая таблица экспериментов

| Этап | Алгоритм/Эвристика | Профиль | Количество запусков | Шаги | Время выполнения |
|------|-------------------|---------|---------------------|------|------------------|
| **Обучение** | | | | | |
| 1.1 | PPO | A | 3 | 960 шагов | 24ч × 3 = 72ч (~3 дня) |
| 1.2 | SAC | A | 3 | 1600 шагов | 24ч × 3 = 72ч (~3 дня) |
| 1.3 | TD3 | A | 3 | 960 шагов | 24ч × 3 = 72ч (~3 дня) |
| 1.4 | Static heuristic | A | 3 | зависит | 24ч × 3 = 72ч (~3 дня) |
| 1.5 | Greedy latency heuristic | A | 3 | зависит | 24ч × 3 = 72ч (~3 дня) |
| **Reconciliation - Стабильность** | | | | | |
| 2.1 | PPO (A) | A | 3 модели | 960 шагов | 24ч × 3 = 72ч (~3 дня) |
| 2.2 | SAC (A) | A | 3 модели | 1600 шагов | 24ч × 3 = 72ч (~3 дня) |
| 2.3 | TD3 (A) | A | 3 модели | 960 шагов | 24ч × 3 = 72ч (~3 дня) |
| **Reconciliation - Обобщение** | | | | | |
| 2.4 | PPO (B) | B | 3 модели | 960 шагов | 24ч × 3 = 72ч (~3 дня) |
| 2.5 | SAC (B) | B | 3 модели | 1600 шагов | 24ч × 3 = 72ч (~3 дня) |
| 2.6 | TD3 (B) | B | 3 модели | 960 шагов | 24ч × 3 = 72ч (~3 дня) |
| **Baseline Reconciliation** | | | | | |
| 2.7 | Static (A) | A (24h) | 1 | 8640 | ~48ч |
| 2.8 | Static (B) | B (24h) | 1 | 8640 | ~48ч |
| 2.9 | Greedy latency (A) | A (24h) | 1 | 8640 | ~48ч |
| 2.10 | Greedy latency (B) | B (24h) | 1 | 8640 | ~48ч |

**Общее время (последовательно):** 
- Обучение: 216 часов (~9 дней)
- Reconciliation: 432 часа (~18 дней)
- **Итого:** ~648 часов (~27 дней)

**С параллелизацией (3 VM):**
- **Обучение:** ~3 дня
  - Для каждого алгоритма: 3 запуска выполняются параллельно на 3 VM
  - Каждый запуск = 24 часа реального времени
  - PPO: 3 прогона параллельно = 1 день
  - SAC: 3 прогона параллельно = 1 день
  - TD3: 3 прогона параллельно = 1 день
  - **Итого:** 3 дня (все алгоритмы можно запускать последовательно или параллельно)
- **Reconciliation:** ~6 дней
  - Всего: 9 моделей × 2 профиля = 18 reconciliation
  - Можно запускать по 3 параллельно на 3 VM
  - 18 reconciliation / 3 VM = 6 батчей по 3 параллельно
  - Каждый батч = 24 часа реального времени
  - **Итого:** 6 × 24 часа = 144 часа = 6 дней
- **Итого:** ~9 дней

**Примечание:** Параллелизация означает запуск экспериментов на 3 VM одновременно. Каждая VM выполняет один эксперимент (обучение или reconciliation). За 24 часа на 3 VM можно выполнить 3 прогона параллельно.

---

## Оптимизация времени выполнения

### Варианты оптимизации:

1. **Уменьшение количества запусков:**
   - Уже используется: 3 запуска на алгоритм (оптимальный баланс статистики и времени)
   - Reconciliation: можно запустить только для лучших 2 моделей (экономия ~33%)

2. **Уменьшение stabilization_time:**
   - 10 секунд → 5 секунд (экономия ~50% времени)
   - Но может повлиять на точность метрик

3. **Параллелизация (3 VM):**
   - Каждая из 3 VM запускает отдельный эксперимент одновременно
   - Для обучения: 3 запуска одного алгоритма выполняются параллельно на 3 VM
   - Для reconciliation: можно запускать по одному на VM последовательно
   - Требуется: доступ к 3 вычислительным узлам/VM

4. **Умный выбор моделей:**
   - Обучить 3 модели, но reconciliation только для лучших 2
   - Экономия ~33% времени на reconciliation

### Рекомендуемый компромисс:

- **Обучение:** 3 запуска на алгоритм (уже используется)
- **Reconciliation:** все 3 модели на обоих профилях (для полной статистики)
- **Stabilization time:** 5 секунд (вместо 10) - экономия ~50% времени
- **Параллелизация:** максимально возможная
  - Минимум: 3 VM для параллельного обучения 3 алгоритмов
  - Оптимально: 9 VM для параллельного обучения всех запусков
  - Reconciliation: можно запускать все параллельно (18 VM для всех reconciliation)

**Итоговое время с параллелизацией (3 VM):**
- Обучение: ~3 дня (каждый алгоритм: 3 прогона параллельно = 1 день)
- Reconciliation: ~6 дней (18 reconciliation / 3 VM = 6 батчей × 24 часа = 6 дней)
- **Итого:** ~9 дней

---

## Примечания

1. **Профиль B:** Нужно создать альтернативный профиль нагрузки. Рекомендуется модифицировать основной профиль (изменить амплитуду или сдвинуть пик).

2. **Параллелизация:** Критически важна для практической выполнимости экспериментов.

3. **Мониторинг:** Использовать Weights & Biases для отслеживания прогресса всех экспериментов.

4. **Воспроизводимость:** Сохранять конфигурации и результаты всех запусков.

5. **Резервное копирование:** Регулярно сохранять веса моделей и результаты экспериментов.

6. **Статистическая значимость:** При уменьшении количества запусков нужно убедиться, что результаты остаются статистически значимыми.
